{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function starmodels.csv_reader_dataset.<locals>.<lambda> at 0x7f0a326f6680> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <bound method starmodels.parse_csv_line of <astronn.datasets.starmodels.starmodels object at 0x7f0ab0115c10>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function starmodels.csv_reader_dataset.<locals>.<lambda> at 0x7f0a2e281ef0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function starmodels.csv_reader_dataset.<locals>.<lambda> at 0x7f0a285d7950> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function starmodels.csv_reader_dataset.<locals>.<lambda> at 0x7f0a285d7680> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function deltascuti.csv_reader_dataset.<locals>.<lambda> at 0x7f0a285d7560> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <bound method deltascuti.parse_csv_line of <astronn.datasets.deltascuti.deltascuti object at 0x7f0a285d2850>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function bedding.csv_reader_dataset.<locals>.<lambda> at 0x7f0a280c3050> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <bound method bedding.parse_csv_line of <astronn.datasets.bedding.bedding object at 0x7f0a28305fd0>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"../../\")\n",
    "\n",
    "from astronn import datasets\n",
    "from astronn import models\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from matplotlib.pyplot import figure\n",
    "from scipy.signal import find_peaks, peak_widths\n",
    "\n",
    "\n",
    "seed_value = 12345\n",
    "import os\n",
    "\n",
    "os.environ[\"PYTHONHASHSEED\"] = str(seed_value)\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "random.seed(seed_value)\n",
    "np.random.seed(seed_value)\n",
    "import tensorflow as tf\n",
    "tf.autograph.set_verbosity(0)\n",
    "\n",
    "# Star model to train\n",
    "star_models = datasets.starmodels()\n",
    "\n",
    "df_train = star_models.load(\n",
    "    #\"/home/roberto/Downloads/evolutionTracks_line/parts_train/*_norm\",\n",
    "    \"/home/roberto/Downloads/evolutionTracks_line/norm8/*_norm\",\n",
    "    batch_size=500,\n",
    "    add_noise=True,\n",
    ")\n",
    "df_validation = star_models.load(\n",
    "    #\"/home/roberto/Downloads/evolutionTracks_line/parts_validation/*_norm\",\n",
    "    \"/home/roberto/Downloads/evolutionTracks_line/nomr8_validation/*_norm\",\n",
    "    batch_size=150,\n",
    "    add_noise=True,\n",
    ")\n",
    "\n",
    "\n",
    "# Read datasets of preprocessed real stars to test\n",
    "df_ds = datasets.deltascuti()\n",
    "deltascuti = df_ds.load(\n",
    "    \"../../astronn/data/deltascuti/preprocessed/*\", batch_size=1\n",
    ")\n",
    "bedding_stars = datasets.bedding()\n",
    "df_bedding = bedding_stars.load(\"../data/bedding/preprocessed/*\", batch_size=1)\n",
    "\n",
    "# Get stars\n",
    "ds_stars = [star for star in deltascuti.take(11)]\n",
    "ds_bedding = [star for star in df_bedding.take(57)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\n# Learn and autoencoder from star models\\nfrom tensorflow.keras import layers\\nfrom keras.models import load_model\\n\\nencoding_dim = 2\\n\\nautoencoder = tf.keras.Sequential(\\n    [\\n        layers.Input(shape=(400, 2)),\\n        layers.Flatten(),\\n        layers.Dense(200),\\n        layers.Dense(\\n            encoding_dim,\\n            name=\"lattent\",\\n            activity_regularizer=tf.keras.regularizers.l1(10e-5),\\n        ),\\n        layers.Dense(200),\\n        layers.Dense(800),\\n        layers.Reshape((400, 2)),\\n    ]\\n)\\n\\n# This model maps an input to its reconstruction\\nopt = tf.keras.optimizers.Adam(learning_rate=0.1)\\nautoencoder.compile(loss=\"binary_crossentropy\", optimizer=opt, metrics=[\"mse\"])\\nautoencoder.summary()\\n\\nautoencoder.fit(\\n    df_train, steps_per_epoch=40, epochs=10, verbose=True,\\n)\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "\n",
    "# Learn and autoencoder from star models\n",
    "from tensorflow.keras import layers\n",
    "from keras.models import load_model\n",
    "\n",
    "encoding_dim = 2\n",
    "\n",
    "autoencoder = tf.keras.Sequential(\n",
    "    [\n",
    "        layers.Input(shape=(400, 2)),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(200),\n",
    "        layers.Dense(\n",
    "            encoding_dim,\n",
    "            name=\"lattent\",\n",
    "            activity_regularizer=tf.keras.regularizers.l1(10e-5),\n",
    "        ),\n",
    "        layers.Dense(200),\n",
    "        layers.Dense(800),\n",
    "        layers.Reshape((400, 2)),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# This model maps an input to its reconstruction\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=0.1)\n",
    "autoencoder.compile(loss=\"binary_crossentropy\", optimizer=opt, metrics=[\"mse\"])\n",
    "autoencoder.summary()\n",
    "\n",
    "autoencoder.fit(\n",
    "    df_train, steps_per_epoch=40, epochs=10, verbose=True,\n",
    ")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ncount = 0\\nfor star in df_train.take(1):\\n    plt.plot(star[0][0, :, 0])\\n    plt.plot(star[0][0, :, 1])\\n    plt.show()\\n    \\nplt.plot(autoencoder.predict(star[0])[0])\\n\\nautoencoder.get_layer(\"lattent\").output\\nautoencoder.save(\"/tmp/autoencoder\")\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "count = 0\n",
    "for star in df_train.take(1):\n",
    "    plt.plot(star[0][0, :, 0])\n",
    "    plt.plot(star[0][0, :, 1])\n",
    "    plt.show()\n",
    "    \n",
    "plt.plot(autoencoder.predict(star[0])[0])\n",
    "\n",
    "autoencoder.get_layer(\"lattent\").output\n",
    "autoencoder.save(\"/tmp/autoencoder\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "#    filepath=\"/tmp/model_checkpoint\",\n",
    "#    save_weights_only=True,\n",
    "#    monitor='val_acc',\n",
    "#    mode='max',\n",
    "#    save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_peak_width(position, peaks, peaks_width, peaks_sorted_by_prob):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    peak_id = np.where(probs == peaks_sorted_by_prob[position])[0][0]\n",
    "    return (peak_id, peaks_width[0][np.where(peaks == peak_id)[0][0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0.0: 0.2, 1.0: 0.2, 2.0: 0.2, 3.0: 0.2, 4.0: 0.2, 5.0: 0.2, 6.0: 0.2, 7.0: 0.2, 8.0: 0.2, 9.0: 0.2, 10.0: 0.2, 11.0: 0.2, 12.0: 0.2, 13.0: 0.2, 14.0: 0.2, 15.0: 0.2, 16.0: 0.2, 17.0: 0.2, 18.0: 0.2, 19.0: 0.2, 20.0: 0.2, 21.0: 0.2, 22.0: 0.2, 23.0: 0.2, 24.0: 0.2, 25.0: 0.2, 26.0: 0.2, 27.0: 0.2, 28.0: 0.2, 29.0: 0.2, 30.0: 0.2, 31.0: 0.2, 32.0: 0.2, 33.0: 0.2, 34.0: 0.2, 35.0: 0.2, 36.0: 0.2, 37.0: 0.2, 38.0: 0.2, 39.0: 0.2, 40.0: 0.2, 41.0: 0.2, 42.0: 0.2, 43.0: 0.2, 44.0: 0.2, 45.0: 0.2, 46.0: 0.2, 47.0: 0.2, 48.0: 0.2, 49.0: 0.2, 50.0: 0.2, 51.0: 0.2, 52.0: 0.2, 53.0: 0.2, 54.0: 0.2, 55.0: 0.2, 56.0: 0.2, 57.0: 0.2, 58.0: 0.2, 59.0: 0.2, 60.0: 0.2, 61.0: 0.2, 62.0: 0.2, 63.0: 0.2, 64.0: 0.2, 65.0: 0.2, 66.0: 0.2, 67.0: 0.2, 68.0: 0.2, 69.0: 0.2, 70.0: 0.2, 71.0: 0.2, 72.0: 0.2, 73.0: 0.2, 74.0: 0.2, 75.0: 0.2, 76.0: 0.2, 77.0: 0.2, 78.0: 0.2, 79.0: 0.2, 80.0: 0.2, 81.0: 0.2, 82.0: 0.2, 83.0: 0.2, 84.0: 0.2, 85.0: 0.2, 86.0: 0.2, 87.0: 0.2, 88.0: 0.2, 89.0: 0.2, 90.0: 0.2, 91.0: 0.2, 92.0: 0.2, 93.0: 0.2, 94.0: 0.2, 95.0: 0.2, 96.0: 0.2, 97.0: 0.2, 98.0: 0.2, 99.0: 0.2}\n",
      "Loop 0\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " gaussian_noise (GaussianNoi  (None, 400, 2)           0         \n",
      " se)                                                             \n",
      "                                                                 \n",
      " conv1d (Conv1D)             (None, 381, 20)           820       \n",
      "                                                                 \n",
      " max_pooling1d (MaxPooling1D  (None, 381, 20)          0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 372, 10)           2010      \n",
      "                                                                 \n",
      " max_pooling1d_1 (MaxPooling  (None, 372, 10)          0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " conv1d_2 (Conv1D)           (None, 363, 5)            505       \n",
      "                                                                 \n",
      " max_pooling1d_2 (MaxPooling  (None, 363, 5)           0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 363, 5)           20        \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 363, 5)            0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 1815)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 100)               181600    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 184,955\n",
      "Trainable params: 184,945\n",
      "Non-trainable params: 10\n",
      "_________________________________________________________________\n",
      "Episode 0\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f0a34281cb0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "10/10 [==============================] - ETA: 0s - loss: 5.3638 - accuracy: 0.0384WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f0a20418050> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "10/10 [==============================] - 5s 387ms/step - loss: 5.3638 - accuracy: 0.0384 - val_loss: 4.9863 - val_accuracy: 0.0133\n",
      "WARNING:tensorflow:AutoGraph could not transform <function trace_model_call.<locals>._wrapped_model at 0x7f0a20467830> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7f0a1aece710> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "INFO:tensorflow:Assets written to: /tmp/sepconvnn_tmp_dos_0/assets\n",
      "Episode 1\n",
      "10/10 [==============================] - 4s 369ms/step - loss: 3.9201 - accuracy: 0.0908 - val_loss: 10.5744 - val_accuracy: 0.0000e+00\n",
      "Episode 2\n",
      "10/10 [==============================] - 4s 373ms/step - loss: 3.6306 - accuracy: 0.1272 - val_loss: 15.6496 - val_accuracy: 0.0000e+00\n",
      "Episode 3\n",
      "10/10 [==============================] - 4s 370ms/step - loss: 3.4919 - accuracy: 0.1396 - val_loss: 18.0105 - val_accuracy: 0.0000e+00\n",
      "Episode 4\n",
      "10/10 [==============================] - 4s 373ms/step - loss: 3.3674 - accuracy: 0.1616 - val_loss: 19.8984 - val_accuracy: 0.0000e+00\n",
      "Episode 5\n",
      "10/10 [==============================] - 4s 374ms/step - loss: 3.2838 - accuracy: 0.1736 - val_loss: 19.1067 - val_accuracy: 0.0000e+00\n",
      "Episode 6\n",
      "10/10 [==============================] - 4s 370ms/step - loss: 3.2191 - accuracy: 0.1856 - val_loss: 18.2752 - val_accuracy: 0.0000e+00\n",
      "Episode 7\n",
      "10/10 [==============================] - 5s 449ms/step - loss: 3.1310 - accuracy: 0.1938 - val_loss: 17.1183 - val_accuracy: 0.0000e+00\n",
      "Episode 8\n",
      "10/10 [==============================] - 4s 373ms/step - loss: 3.0527 - accuracy: 0.2020 - val_loss: 15.8457 - val_accuracy: 0.0000e+00\n",
      "Episode 9\n",
      "10/10 [==============================] - 4s 368ms/step - loss: 2.9694 - accuracy: 0.2156 - val_loss: 15.8015 - val_accuracy: 0.0000e+00\n",
      "Episode 10\n",
      "10/10 [==============================] - 4s 371ms/step - loss: 2.9379 - accuracy: 0.2172 - val_loss: 16.6146 - val_accuracy: 0.0000e+00\n",
      "Episode 11\n",
      "10/10 [==============================] - 4s 372ms/step - loss: 2.9025 - accuracy: 0.2182 - val_loss: 13.6356 - val_accuracy: 0.0000e+00\n",
      "Episode 12\n",
      "10/10 [==============================] - 4s 369ms/step - loss: 2.8226 - accuracy: 0.2276 - val_loss: 14.0236 - val_accuracy: 0.0000e+00\n",
      "Episode 13\n",
      "10/10 [==============================] - 4s 375ms/step - loss: 2.7758 - accuracy: 0.2324 - val_loss: 14.2293 - val_accuracy: 0.0000e+00\n",
      "Episode 14\n",
      "10/10 [==============================] - 4s 370ms/step - loss: 2.7817 - accuracy: 0.2312 - val_loss: 12.2156 - val_accuracy: 0.0000e+00\n",
      "Episode 15\n",
      "10/10 [==============================] - 4s 431ms/step - loss: 2.7981 - accuracy: 0.2324 - val_loss: 11.9917 - val_accuracy: 0.0000e+00\n",
      "Episode 16\n",
      "10/10 [==============================] - 4s 376ms/step - loss: 2.7612 - accuracy: 0.2454 - val_loss: 10.3825 - val_accuracy: 0.0000e+00\n",
      "Episode 17\n",
      "10/10 [==============================] - 4s 369ms/step - loss: 2.6960 - accuracy: 0.2504 - val_loss: 12.1739 - val_accuracy: 0.0000e+00\n",
      "Episode 18\n",
      "10/10 [==============================] - 4s 377ms/step - loss: 2.7741 - accuracy: 0.2334 - val_loss: 11.3594 - val_accuracy: 0.0000e+00\n",
      "Episode 19\n",
      "10/10 [==============================] - 4s 368ms/step - loss: 2.7161 - accuracy: 0.2440 - val_loss: 9.7148 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 20\n",
      "10/10 [==============================] - 4s 372ms/step - loss: 2.6889 - accuracy: 0.2490 - val_loss: 10.0106 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:AutoGraph could not transform <function trace_model_call.<locals>._wrapped_model at 0x7f0a28553560> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7f0a1af8b170> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "INFO:tensorflow:Assets written to: /tmp/sepconvnn_tmp_dos_20/assets\n",
      "Episode 21\n",
      "10/10 [==============================] - 4s 383ms/step - loss: 2.6967 - accuracy: 0.2456 - val_loss: 8.3088 - val_accuracy: 0.0000e+00\n",
      "Episode 22\n",
      "10/10 [==============================] - 4s 375ms/step - loss: 2.7419 - accuracy: 0.2396 - val_loss: 9.7868 - val_accuracy: 0.0000e+00\n",
      "Episode 23\n",
      "10/10 [==============================] - 4s 367ms/step - loss: 2.7014 - accuracy: 0.2448 - val_loss: 8.2567 - val_accuracy: 0.0000e+00\n",
      "Episode 24\n",
      "10/10 [==============================] - 4s 374ms/step - loss: 2.6849 - accuracy: 0.2472 - val_loss: 7.5186 - val_accuracy: 0.0000e+00\n",
      "Episode 25\n",
      "10/10 [==============================] - 4s 372ms/step - loss: 2.7014 - accuracy: 0.2472 - val_loss: 8.3171 - val_accuracy: 0.0000e+00\n",
      "Episode 26\n",
      "10/10 [==============================] - 4s 372ms/step - loss: 2.6797 - accuracy: 0.2500 - val_loss: 7.8606 - val_accuracy: 0.0000e+00\n",
      "Episode 27\n",
      "10/10 [==============================] - 4s 373ms/step - loss: 2.6629 - accuracy: 0.2548 - val_loss: 7.1561 - val_accuracy: 0.0000e+00\n",
      "Episode 28\n",
      "10/10 [==============================] - 4s 371ms/step - loss: 2.6593 - accuracy: 0.2534 - val_loss: 6.7674 - val_accuracy: 0.0000e+00\n",
      "Episode 29\n",
      "10/10 [==============================] - 4s 370ms/step - loss: 2.6808 - accuracy: 0.2514 - val_loss: 6.5287 - val_accuracy: 0.0000e+00\n",
      "Episode 30\n",
      "10/10 [==============================] - 4s 372ms/step - loss: 2.6322 - accuracy: 0.2604 - val_loss: 5.8180 - val_accuracy: 0.0000e+00\n",
      "Episode 31\n",
      "10/10 [==============================] - 4s 371ms/step - loss: 2.6717 - accuracy: 0.2676 - val_loss: 6.2536 - val_accuracy: 0.0000e+00\n",
      "Episode 32\n",
      "10/10 [==============================] - 4s 367ms/step - loss: 2.6396 - accuracy: 0.2562 - val_loss: 5.6321 - val_accuracy: 0.0000e+00\n",
      "Episode 33\n",
      "10/10 [==============================] - 4s 369ms/step - loss: 2.6206 - accuracy: 0.2658 - val_loss: 5.7479 - val_accuracy: 0.0000e+00\n",
      "Episode 34\n",
      "10/10 [==============================] - 4s 373ms/step - loss: 2.6384 - accuracy: 0.2518 - val_loss: 5.8229 - val_accuracy: 0.0000e+00\n",
      "Episode 35\n",
      "10/10 [==============================] - 4s 372ms/step - loss: 2.5849 - accuracy: 0.2666 - val_loss: 4.1265 - val_accuracy: 0.0533\n",
      "Episode 36\n",
      "10/10 [==============================] - 4s 372ms/step - loss: 2.6509 - accuracy: 0.2604 - val_loss: 6.3482 - val_accuracy: 0.0000e+00\n",
      "Episode 37\n",
      "10/10 [==============================] - 4s 368ms/step - loss: 2.6181 - accuracy: 0.2582 - val_loss: 4.4915 - val_accuracy: 0.0133\n",
      "Episode 38\n",
      "10/10 [==============================] - 4s 372ms/step - loss: 2.5892 - accuracy: 0.2694 - val_loss: 4.3331 - val_accuracy: 0.0200\n",
      "Episode 39\n",
      "10/10 [==============================] - 4s 374ms/step - loss: 2.5322 - accuracy: 0.2874 - val_loss: 2.7917 - val_accuracy: 0.2000\n",
      "Episode 58\n",
      "10/10 [==============================] - 4s 373ms/step - loss: 2.5619 - accuracy: 0.2560 - val_loss: 3.5724 - val_accuracy: 0.1133\n",
      "Episode 59\n",
      "10/10 [==============================] - 4s 374ms/step - loss: 2.5157 - accuracy: 0.2880 - val_loss: 3.1079 - val_accuracy: 0.2067\n",
      "Episode 60\n",
      "10/10 [==============================] - 4s 370ms/step - loss: 2.4829 - accuracy: 0.2816 - val_loss: 3.7698 - val_accuracy: 0.1400\n",
      "WARNING:tensorflow:AutoGraph could not transform <function trace_model_call.<locals>._wrapped_model at 0x7f0a20467830> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7f0a1aa853b0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "INFO:tensorflow:Assets written to: /tmp/sepconvnn_tmp_dos_60/assets\n",
      "Episode 61\n",
      "10/10 [==============================] - 4s 370ms/step - loss: 2.5567 - accuracy: 0.2660 - val_loss: 4.0470 - val_accuracy: 0.0933\n",
      "Episode 62\n",
      "10/10 [==============================] - 4s 371ms/step - loss: 2.4970 - accuracy: 0.2908 - val_loss: 3.9282 - val_accuracy: 0.1800\n",
      "Episode 63\n",
      "10/10 [==============================] - 4s 375ms/step - loss: 2.5114 - accuracy: 0.2782 - val_loss: 3.7918 - val_accuracy: 0.0600\n",
      "Episode 64\n",
      "10/10 [==============================] - 4s 370ms/step - loss: 2.5297 - accuracy: 0.2806 - val_loss: 3.2237 - val_accuracy: 0.2200\n",
      "Episode 65\n",
      "10/10 [==============================] - 4s 373ms/step - loss: 2.5144 - accuracy: 0.2732 - val_loss: 3.1132 - val_accuracy: 0.2333\n",
      "Episode 66\n",
      "10/10 [==============================] - 4s 374ms/step - loss: 2.5030 - accuracy: 0.2872 - val_loss: 2.6423 - val_accuracy: 0.3133\n",
      "Episode 67\n",
      "10/10 [==============================] - 4s 375ms/step - loss: 2.4932 - accuracy: 0.2816 - val_loss: 2.3919 - val_accuracy: 0.2933\n",
      "Episode 68\n",
      "10/10 [==============================] - 4s 368ms/step - loss: 2.4953 - accuracy: 0.2908 - val_loss: 2.5037 - val_accuracy: 0.2933\n",
      "Episode 69\n",
      "10/10 [==============================] - 4s 371ms/step - loss: 2.4714 - accuracy: 0.2846 - val_loss: 2.5645 - val_accuracy: 0.2733\n",
      "Episode 70\n",
      "10/10 [==============================] - 4s 370ms/step - loss: 2.5020 - accuracy: 0.2764 - val_loss: 2.2541 - val_accuracy: 0.3867\n",
      "Episode 71\n",
      "10/10 [==============================] - 4s 371ms/step - loss: 2.5133 - accuracy: 0.2678 - val_loss: 2.4926 - val_accuracy: 0.2867\n",
      "Episode 72\n",
      "10/10 [==============================] - 4s 368ms/step - loss: 2.4909 - accuracy: 0.2836 - val_loss: 3.6702 - val_accuracy: 0.2200\n",
      "Episode 73\n",
      "10/10 [==============================] - 4s 405ms/step - loss: 2.4923 - accuracy: 0.2772 - val_loss: 2.2502 - val_accuracy: 0.3533\n",
      "Episode 74\n",
      "10/10 [==============================] - 6s 551ms/step - loss: 2.5019 - accuracy: 0.2766 - val_loss: 2.3409 - val_accuracy: 0.3600\n",
      "Episode 75\n",
      "10/10 [==============================] - 5s 445ms/step - loss: 2.5101 - accuracy: 0.2796 - val_loss: 2.8331 - val_accuracy: 0.2000\n",
      "Episode 76\n",
      "10/10 [==============================] - 4s 373ms/step - loss: 2.4951 - accuracy: 0.2728 - val_loss: 3.4170 - val_accuracy: 0.2400\n",
      "Episode 77\n",
      "10/10 [==============================] - 4s 394ms/step - loss: 2.4343 - accuracy: 0.2874 - val_loss: 2.4860 - val_accuracy: 0.2533\n",
      "Episode 78\n",
      "10/10 [==============================] - 4s 399ms/step - loss: 2.4838 - accuracy: 0.2886 - val_loss: 6.7076 - val_accuracy: 0.0000e+00\n",
      "Episode 79\n",
      "10/10 [==============================] - 4s 373ms/step - loss: 2.4675 - accuracy: 0.2856 - val_loss: 2.3515 - val_accuracy: 0.3533\n",
      "Episode 80\n",
      "10/10 [==============================] - 4s 415ms/step - loss: 2.4713 - accuracy: 0.2754 - val_loss: 2.4837 - val_accuracy: 0.3000\n",
      "WARNING:tensorflow:AutoGraph could not transform <function trace_model_call.<locals>._wrapped_model at 0x7f0a20467830> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7f0a1a81ccb0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "INFO:tensorflow:Assets written to: /tmp/sepconvnn_tmp_dos_80/assets\n",
      "Episode 81\n",
      "10/10 [==============================] - 4s 373ms/step - loss: 2.4514 - accuracy: 0.2850 - val_loss: 2.3425 - val_accuracy: 0.3467\n",
      "Episode 82\n",
      "10/10 [==============================] - 4s 373ms/step - loss: 2.4355 - accuracy: 0.2966 - val_loss: 3.0555 - val_accuracy: 0.2400\n",
      "Episode 83\n",
      "10/10 [==============================] - 4s 374ms/step - loss: 2.4583 - accuracy: 0.2940 - val_loss: 2.2920 - val_accuracy: 0.3000\n",
      "Episode 84\n",
      "10/10 [==============================] - 4s 369ms/step - loss: 2.4859 - accuracy: 0.2750 - val_loss: 2.4856 - val_accuracy: 0.2600\n",
      "Episode 85\n",
      "10/10 [==============================] - 4s 371ms/step - loss: 2.4129 - accuracy: 0.2920 - val_loss: 2.3917 - val_accuracy: 0.2800\n",
      "Episode 86\n",
      "10/10 [==============================] - 4s 370ms/step - loss: 2.4630 - accuracy: 0.2900 - val_loss: 2.6373 - val_accuracy: 0.2933\n",
      "Episode 87\n",
      "10/10 [==============================] - 4s 377ms/step - loss: 2.4633 - accuracy: 0.2784 - val_loss: 2.4700 - val_accuracy: 0.3200\n",
      "Episode 88\n",
      "10/10 [==============================] - 4s 369ms/step - loss: 2.4294 - accuracy: 0.2920 - val_loss: 2.3674 - val_accuracy: 0.3467\n",
      "Episode 89\n",
      "10/10 [==============================] - 4s 371ms/step - loss: 2.4225 - accuracy: 0.2846 - val_loss: 4.2589 - val_accuracy: 0.1200\n",
      "Episode 90\n",
      "10/10 [==============================] - 4s 370ms/step - loss: 2.4491 - accuracy: 0.2848 - val_loss: 2.1776 - val_accuracy: 0.3533\n",
      "Episode 91\n",
      "10/10 [==============================] - 4s 370ms/step - loss: 2.4086 - accuracy: 0.2934 - val_loss: 2.3417 - val_accuracy: 0.2800\n",
      "Episode 92\n",
      "10/10 [==============================] - 4s 370ms/step - loss: 2.4361 - accuracy: 0.3110 - val_loss: 2.5478 - val_accuracy: 0.3067\n",
      "Episode 93\n",
      "10/10 [==============================] - 4s 374ms/step - loss: 2.4355 - accuracy: 0.2926 - val_loss: 2.1203 - val_accuracy: 0.2733\n",
      "Episode 94\n",
      "10/10 [==============================] - 4s 374ms/step - loss: 2.4120 - accuracy: 0.3040 - val_loss: 2.7560 - val_accuracy: 0.2600\n",
      "Episode 95\n",
      "10/10 [==============================] - 4s 371ms/step - loss: 2.4218 - accuracy: 0.3016 - val_loss: 2.6617 - val_accuracy: 0.2267\n",
      "Episode 96\n",
      "10/10 [==============================] - 4s 372ms/step - loss: 2.4186 - accuracy: 0.2956 - val_loss: 2.2990 - val_accuracy: 0.3200\n",
      "Episode 97\n",
      "10/10 [==============================] - 4s 370ms/step - loss: 2.3990 - accuracy: 0.2968 - val_loss: 2.2110 - val_accuracy: 0.2800\n",
      "Episode 98\n",
      "10/10 [==============================] - 4s 371ms/step - loss: 2.3912 - accuracy: 0.2978 - val_loss: 2.3003 - val_accuracy: 0.3000\n",
      "Episode 99\n",
      "10/10 [==============================] - 4s 370ms/step - loss: 2.4083 - accuracy: 0.3008 - val_loss: 2.0454 - val_accuracy: 0.3667\n",
      "Episode 100\n",
      "10/10 [==============================] - 4s 422ms/step - loss: 2.3968 - accuracy: 0.3012 - val_loss: 2.4655 - val_accuracy: 0.3067\n",
      "WARNING:tensorflow:AutoGraph could not transform <function trace_model_call.<locals>._wrapped_model at 0x7f0a1a606c20> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7f0a1a402d40> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "INFO:tensorflow:Assets written to: /tmp/sepconvnn_tmp_dos_100/assets\n",
      "Episode 101\n",
      "10/10 [==============================] - 4s 374ms/step - loss: 2.4161 - accuracy: 0.2978 - val_loss: 2.5919 - val_accuracy: 0.2667\n",
      "Episode 102\n",
      "10/10 [==============================] - 4s 373ms/step - loss: 2.3962 - accuracy: 0.2984 - val_loss: 2.2616 - val_accuracy: 0.3000\n",
      "Episode 103\n",
      "10/10 [==============================] - 4s 376ms/step - loss: 2.3999 - accuracy: 0.3070 - val_loss: 2.6456 - val_accuracy: 0.2533\n",
      "Episode 104\n",
      "10/10 [==============================] - 4s 376ms/step - loss: 2.3884 - accuracy: 0.3018 - val_loss: 2.1294 - val_accuracy: 0.3067\n",
      "Episode 105\n",
      "10/10 [==============================] - 4s 372ms/step - loss: 2.3662 - accuracy: 0.3126 - val_loss: 2.1953 - val_accuracy: 0.3467\n",
      "Episode 106\n",
      "10/10 [==============================] - 4s 376ms/step - loss: 2.3561 - accuracy: 0.3062 - val_loss: 2.3896 - val_accuracy: 0.2600\n",
      "Episode 107\n",
      "10/10 [==============================] - 4s 377ms/step - loss: 2.3288 - accuracy: 0.3038 - val_loss: 2.2279 - val_accuracy: 0.3733\n",
      "Episode 108\n",
      "10/10 [==============================] - 4s 378ms/step - loss: 2.3685 - accuracy: 0.3050 - val_loss: 2.1456 - val_accuracy: 0.3400\n",
      "Episode 109\n",
      "10/10 [==============================] - 5s 466ms/step - loss: 2.3427 - accuracy: 0.3044 - val_loss: 2.1668 - val_accuracy: 0.3400\n",
      "Episode 110\n",
      "10/10 [==============================] - 4s 376ms/step - loss: 2.3491 - accuracy: 0.3042 - val_loss: 2.2741 - val_accuracy: 0.3200\n",
      "Episode 111\n",
      "10/10 [==============================] - 4s 376ms/step - loss: 2.3549 - accuracy: 0.3034 - val_loss: 2.1202 - val_accuracy: 0.3200\n",
      "Episode 112\n",
      "10/10 [==============================] - 4s 373ms/step - loss: 2.3458 - accuracy: 0.2952 - val_loss: 2.3498 - val_accuracy: 0.2867\n",
      "Episode 113\n",
      "10/10 [==============================] - 4s 374ms/step - loss: 2.2935 - accuracy: 0.3078 - val_loss: 2.4137 - val_accuracy: 0.2533\n",
      "Episode 114\n",
      "10/10 [==============================] - 4s 371ms/step - loss: 2.3143 - accuracy: 0.3120 - val_loss: 2.3542 - val_accuracy: 0.3533\n",
      "Episode 115\n",
      "10/10 [==============================] - 4s 375ms/step - loss: 2.3162 - accuracy: 0.3054 - val_loss: 2.1854 - val_accuracy: 0.2867\n",
      "Episode 116\n",
      "10/10 [==============================] - 4s 374ms/step - loss: 2.3385 - accuracy: 0.3124 - val_loss: 2.1055 - val_accuracy: 0.2867\n",
      "Episode 117\n",
      "10/10 [==============================] - 4s 390ms/step - loss: 2.3507 - accuracy: 0.3060 - val_loss: 2.0211 - val_accuracy: 0.3133\n",
      "Episode 118\n",
      "10/10 [==============================] - 4s 371ms/step - loss: 2.3021 - accuracy: 0.3112 - val_loss: 2.2509 - val_accuracy: 0.3467\n",
      "Episode 119\n",
      "10/10 [==============================] - 4s 374ms/step - loss: 2.3352 - accuracy: 0.3026 - val_loss: 2.3210 - val_accuracy: 0.3000\n",
      "Episode 120\n",
      "10/10 [==============================] - 4s 373ms/step - loss: 2.2800 - accuracy: 0.3214 - val_loss: 2.0852 - val_accuracy: 0.3667\n",
      "WARNING:tensorflow:AutoGraph could not transform <function trace_model_call.<locals>._wrapped_model at 0x7f0a20467830> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7f0a1aefd680> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "INFO:tensorflow:Assets written to: /tmp/sepconvnn_tmp_dos_120/assets\n",
      "Episode 121\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 4s 368ms/step - loss: 2.2956 - accuracy: 0.3134 - val_loss: 2.0433 - val_accuracy: 0.4000\n",
      "Episode 122\n",
      "10/10 [==============================] - 4s 370ms/step - loss: 2.3140 - accuracy: 0.3106 - val_loss: 2.1920 - val_accuracy: 0.3067\n",
      "Episode 123\n",
      "10/10 [==============================] - 4s 368ms/step - loss: 2.3144 - accuracy: 0.3206 - val_loss: 1.9860 - val_accuracy: 0.3533\n",
      "Episode 124\n",
      "10/10 [==============================] - 4s 372ms/step - loss: 2.2729 - accuracy: 0.3056 - val_loss: 2.2586 - val_accuracy: 0.3067\n",
      "Episode 125\n",
      "10/10 [==============================] - 4s 370ms/step - loss: 2.2760 - accuracy: 0.3082 - val_loss: 2.4462 - val_accuracy: 0.3133\n",
      "Episode 126\n",
      "10/10 [==============================] - 4s 372ms/step - loss: 2.2500 - accuracy: 0.3152 - val_loss: 2.3191 - val_accuracy: 0.2933\n",
      "Episode 127\n",
      "10/10 [==============================] - 5s 455ms/step - loss: 2.2722 - accuracy: 0.3172 - val_loss: 1.9898 - val_accuracy: 0.3333\n",
      "Episode 128\n",
      "10/10 [==============================] - 4s 397ms/step - loss: 2.2497 - accuracy: 0.3040 - val_loss: 2.0853 - val_accuracy: 0.3333\n",
      "Episode 129\n",
      "10/10 [==============================] - 4s 373ms/step - loss: 2.2612 - accuracy: 0.2992 - val_loss: 2.1600 - val_accuracy: 0.3133\n",
      "Episode 130\n",
      "10/10 [==============================] - 4s 373ms/step - loss: 2.2509 - accuracy: 0.3166 - val_loss: 1.8983 - val_accuracy: 0.4267\n",
      "Episode 131\n",
      "10/10 [==============================] - 4s 373ms/step - loss: 2.2930 - accuracy: 0.3082 - val_loss: 2.1257 - val_accuracy: 0.3533\n",
      "Episode 132\n",
      "10/10 [==============================] - 4s 369ms/step - loss: 2.2561 - accuracy: 0.3214 - val_loss: 2.0894 - val_accuracy: 0.3733\n",
      "Episode 133\n",
      "10/10 [==============================] - 4s 369ms/step - loss: 2.2384 - accuracy: 0.3216 - val_loss: 1.9645 - val_accuracy: 0.3200\n",
      "Episode 134\n",
      "10/10 [==============================] - 4s 371ms/step - loss: 2.2861 - accuracy: 0.3094 - val_loss: 2.0455 - val_accuracy: 0.3267\n",
      "Episode 135\n",
      "10/10 [==============================] - 4s 373ms/step - loss: 2.2507 - accuracy: 0.3138 - val_loss: 1.9407 - val_accuracy: 0.3667\n",
      "Episode 136\n",
      "10/10 [==============================] - 4s 372ms/step - loss: 2.2540 - accuracy: 0.3034 - val_loss: 1.9673 - val_accuracy: 0.3267\n",
      "Episode 137\n",
      "10/10 [==============================] - 4s 375ms/step - loss: 2.2376 - accuracy: 0.3240 - val_loss: 2.0577 - val_accuracy: 0.3000\n",
      "Episode 138\n",
      "10/10 [==============================] - 4s 371ms/step - loss: 2.2678 - accuracy: 0.3214 - val_loss: 1.8778 - val_accuracy: 0.3667\n",
      "Episode 139\n",
      "10/10 [==============================] - 4s 386ms/step - loss: 2.2367 - accuracy: 0.3188 - val_loss: 1.9485 - val_accuracy: 0.3533\n",
      "Episode 140\n",
      "10/10 [==============================] - 4s 397ms/step - loss: 2.2547 - accuracy: 0.3164 - val_loss: 1.7719 - val_accuracy: 0.4667\n",
      "WARNING:tensorflow:AutoGraph could not transform <function trace_model_call.<locals>._wrapped_model at 0x7f0a28553560> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7f0a1a8e7680> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "INFO:tensorflow:Assets written to: /tmp/sepconvnn_tmp_dos_140/assets\n",
      "Episode 141\n",
      "10/10 [==============================] - 4s 389ms/step - loss: 2.1980 - accuracy: 0.3332 - val_loss: 2.1126 - val_accuracy: 0.3600\n",
      "Episode 142\n",
      "10/10 [==============================] - 4s 372ms/step - loss: 2.2756 - accuracy: 0.3194 - val_loss: 2.1830 - val_accuracy: 0.3267\n",
      "Episode 143\n",
      "10/10 [==============================] - 4s 375ms/step - loss: 2.2474 - accuracy: 0.3170 - val_loss: 1.9318 - val_accuracy: 0.3667\n",
      "Episode 144\n",
      "10/10 [==============================] - 4s 373ms/step - loss: 2.2619 - accuracy: 0.3196 - val_loss: 2.0581 - val_accuracy: 0.3733\n",
      "Episode 145\n",
      "10/10 [==============================] - 4s 373ms/step - loss: 2.2304 - accuracy: 0.3178 - val_loss: 2.1291 - val_accuracy: 0.3333\n",
      "Episode 146\n",
      "10/10 [==============================] - 4s 379ms/step - loss: 2.2157 - accuracy: 0.3184 - val_loss: 2.0823 - val_accuracy: 0.3400\n",
      "Episode 147\n",
      "10/10 [==============================] - 4s 372ms/step - loss: 2.2181 - accuracy: 0.3234 - val_loss: 1.9207 - val_accuracy: 0.3800\n",
      "Episode 148\n",
      "10/10 [==============================] - 4s 371ms/step - loss: 2.1977 - accuracy: 0.3346 - val_loss: 1.9832 - val_accuracy: 0.4133\n",
      "Episode 149\n",
      "10/10 [==============================] - 4s 372ms/step - loss: 2.2420 - accuracy: 0.3120 - val_loss: 1.7772 - val_accuracy: 0.4267\n",
      "Episode 150\n",
      "10/10 [==============================] - 4s 373ms/step - loss: 2.2174 - accuracy: 0.3258 - val_loss: 2.0390 - val_accuracy: 0.3333\n",
      "Episode 151\n",
      "10/10 [==============================] - 4s 366ms/step - loss: 2.2638 - accuracy: 0.3176 - val_loss: 2.1480 - val_accuracy: 0.3467\n",
      "Episode 152\n",
      "10/10 [==============================] - 4s 374ms/step - loss: 2.2484 - accuracy: 0.3216 - val_loss: 2.3299 - val_accuracy: 0.2867\n",
      "Episode 153\n",
      "10/10 [==============================] - 4s 368ms/step - loss: 2.2066 - accuracy: 0.3276 - val_loss: 2.0036 - val_accuracy: 0.3000\n",
      "Episode 154\n",
      "10/10 [==============================] - 4s 378ms/step - loss: 2.2361 - accuracy: 0.3198 - val_loss: 1.8641 - val_accuracy: 0.4067\n",
      "Episode 155\n",
      "10/10 [==============================] - 5s 489ms/step - loss: 2.2353 - accuracy: 0.3192 - val_loss: 1.8771 - val_accuracy: 0.4333\n",
      "Episode 156\n",
      "10/10 [==============================] - 4s 378ms/step - loss: 2.2245 - accuracy: 0.3186 - val_loss: 2.3249 - val_accuracy: 0.2200\n",
      "Episode 157\n",
      "10/10 [==============================] - 4s 376ms/step - loss: 2.2156 - accuracy: 0.3292 - val_loss: 2.0248 - val_accuracy: 0.3333\n",
      "Episode 158\n",
      "10/10 [==============================] - 4s 377ms/step - loss: 2.2148 - accuracy: 0.3238 - val_loss: 2.0923 - val_accuracy: 0.3467\n",
      "Episode 159\n",
      "10/10 [==============================] - 4s 374ms/step - loss: 2.2315 - accuracy: 0.3272 - val_loss: 2.2651 - val_accuracy: 0.3133\n",
      "Episode 160\n",
      "10/10 [==============================] - 4s 370ms/step - loss: 2.1931 - accuracy: 0.3294 - val_loss: 2.0854 - val_accuracy: 0.3533\n",
      "WARNING:tensorflow:AutoGraph could not transform <function trace_model_call.<locals>._wrapped_model at 0x7f0a2836a440> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7f0a1ae4b950> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "INFO:tensorflow:Assets written to: /tmp/sepconvnn_tmp_dos_160/assets\n",
      "Episode 161\n",
      "10/10 [==============================] - 4s 374ms/step - loss: 2.2324 - accuracy: 0.3216 - val_loss: 2.1091 - val_accuracy: 0.3467\n",
      "Episode 162\n",
      "10/10 [==============================] - 4s 373ms/step - loss: 2.2100 - accuracy: 0.3136 - val_loss: 1.8834 - val_accuracy: 0.3800\n",
      "Episode 163\n",
      "10/10 [==============================] - 4s 387ms/step - loss: 2.2386 - accuracy: 0.3308 - val_loss: 2.0283 - val_accuracy: 0.3333\n",
      "Episode 164\n",
      "10/10 [==============================] - 4s 413ms/step - loss: 2.2147 - accuracy: 0.3220 - val_loss: 1.9561 - val_accuracy: 0.3800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 165\n",
      "10/10 [==============================] - 5s 449ms/step - loss: 2.1858 - accuracy: 0.3326 - val_loss: 1.9956 - val_accuracy: 0.3133\n",
      "Episode 166\n",
      "10/10 [==============================] - 4s 374ms/step - loss: 2.2230 - accuracy: 0.3114 - val_loss: 1.8891 - val_accuracy: 0.4067\n",
      "Episode 167\n",
      "10/10 [==============================] - 4s 372ms/step - loss: 2.2244 - accuracy: 0.3240 - val_loss: 2.0833 - val_accuracy: 0.3867\n",
      "Episode 168\n",
      "10/10 [==============================] - 4s 371ms/step - loss: 2.2147 - accuracy: 0.3310 - val_loss: 1.8856 - val_accuracy: 0.4000\n",
      "Episode 169\n",
      "10/10 [==============================] - 4s 371ms/step - loss: 2.2141 - accuracy: 0.3250 - val_loss: 1.9486 - val_accuracy: 0.3667\n",
      "Episode 170\n",
      "10/10 [==============================] - 4s 371ms/step - loss: 2.1772 - accuracy: 0.3320 - val_loss: 1.9355 - val_accuracy: 0.3867\n",
      "Episode 171\n",
      "10/10 [==============================] - 4s 372ms/step - loss: 2.2089 - accuracy: 0.3352 - val_loss: 1.9263 - val_accuracy: 0.3667\n",
      "Episode 172\n",
      "10/10 [==============================] - 4s 372ms/step - loss: 2.1918 - accuracy: 0.3244 - val_loss: 2.3766 - val_accuracy: 0.2400\n",
      "Episode 173\n",
      "10/10 [==============================] - 4s 373ms/step - loss: 2.2088 - accuracy: 0.3248 - val_loss: 2.1039 - val_accuracy: 0.3467\n",
      "Episode 174\n",
      "10/10 [==============================] - 4s 370ms/step - loss: 2.2076 - accuracy: 0.3140 - val_loss: 2.0246 - val_accuracy: 0.2933\n",
      "Episode 175\n",
      "10/10 [==============================] - 4s 374ms/step - loss: 2.1962 - accuracy: 0.3238 - val_loss: 2.0416 - val_accuracy: 0.3600\n",
      "Episode 176\n",
      "10/10 [==============================] - 4s 373ms/step - loss: 2.1710 - accuracy: 0.3280 - val_loss: 2.0252 - val_accuracy: 0.3667\n",
      "Episode 177\n",
      "10/10 [==============================] - 4s 369ms/step - loss: 2.1841 - accuracy: 0.3294 - val_loss: 1.9482 - val_accuracy: 0.3600\n",
      "Episode 178\n",
      "10/10 [==============================] - 4s 370ms/step - loss: 2.1752 - accuracy: 0.3268 - val_loss: 2.0984 - val_accuracy: 0.3400\n",
      "Episode 179\n",
      "10/10 [==============================] - 4s 370ms/step - loss: 2.2013 - accuracy: 0.3222 - val_loss: 2.0511 - val_accuracy: 0.3533\n",
      "Episode 180\n",
      "10/10 [==============================] - 4s 374ms/step - loss: 2.1978 - accuracy: 0.3342 - val_loss: 2.0934 - val_accuracy: 0.3600\n",
      "WARNING:tensorflow:AutoGraph could not transform <function trace_model_call.<locals>._wrapped_model at 0x7f0a20467830> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7f0a1a7289e0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "INFO:tensorflow:Assets written to: /tmp/sepconvnn_tmp_dos_180/assets\n",
      "Episode 181\n",
      "10/10 [==============================] - 4s 376ms/step - loss: 2.1525 - accuracy: 0.3342 - val_loss: 2.0124 - val_accuracy: 0.3800\n",
      "Episode 182\n",
      "10/10 [==============================] - 5s 495ms/step - loss: 2.1916 - accuracy: 0.3346 - val_loss: 1.9254 - val_accuracy: 0.4200\n",
      "Episode 183\n",
      "10/10 [==============================] - 4s 396ms/step - loss: 2.1759 - accuracy: 0.3306 - val_loss: 1.7692 - val_accuracy: 0.4200\n",
      "Episode 184\n",
      "10/10 [==============================] - 4s 372ms/step - loss: 2.1802 - accuracy: 0.3310 - val_loss: 2.0993 - val_accuracy: 0.3867\n",
      "Episode 185\n",
      "10/10 [==============================] - 4s 373ms/step - loss: 2.1847 - accuracy: 0.3184 - val_loss: 1.9729 - val_accuracy: 0.3600\n",
      "Episode 186\n",
      "10/10 [==============================] - 4s 377ms/step - loss: 2.2001 - accuracy: 0.3344 - val_loss: 1.9169 - val_accuracy: 0.3533\n",
      "Episode 187\n",
      "10/10 [==============================] - 4s 372ms/step - loss: 2.1472 - accuracy: 0.3420 - val_loss: 1.9918 - val_accuracy: 0.3733\n",
      "Episode 188\n",
      "10/10 [==============================] - 4s 373ms/step - loss: 2.1786 - accuracy: 0.3310 - val_loss: 2.0181 - val_accuracy: 0.3733\n",
      "Episode 189\n",
      "10/10 [==============================] - 4s 374ms/step - loss: 2.1670 - accuracy: 0.3384 - val_loss: 2.0804 - val_accuracy: 0.3667\n",
      "Episode 190\n",
      "10/10 [==============================] - 4s 372ms/step - loss: 2.2255 - accuracy: 0.3138 - val_loss: 2.1193 - val_accuracy: 0.3733\n",
      "Episode 191\n",
      "10/10 [==============================] - 4s 375ms/step - loss: 2.1756 - accuracy: 0.3270 - val_loss: 1.9940 - val_accuracy: 0.3200\n",
      "Episode 192\n",
      "10/10 [==============================] - 5s 472ms/step - loss: 2.1701 - accuracy: 0.3336 - val_loss: 1.9828 - val_accuracy: 0.3867\n",
      "Episode 193\n",
      "10/10 [==============================] - 4s 373ms/step - loss: 2.1618 - accuracy: 0.3332 - val_loss: 2.0994 - val_accuracy: 0.3733\n",
      "Episode 194\n",
      "10/10 [==============================] - 4s 369ms/step - loss: 2.2015 - accuracy: 0.3288 - val_loss: 1.8660 - val_accuracy: 0.3800\n",
      "Episode 195\n",
      "10/10 [==============================] - 4s 371ms/step - loss: 2.1707 - accuracy: 0.3318 - val_loss: 1.6210 - val_accuracy: 0.4200\n",
      "Episode 196\n",
      "10/10 [==============================] - 4s 372ms/step - loss: 2.1927 - accuracy: 0.3296 - val_loss: 1.9461 - val_accuracy: 0.3533\n",
      "Episode 197\n",
      "10/10 [==============================] - 4s 369ms/step - loss: 2.1887 - accuracy: 0.3368 - val_loss: 1.8419 - val_accuracy: 0.3800\n",
      "Episode 198\n",
      "10/10 [==============================] - 4s 406ms/step - loss: 2.1593 - accuracy: 0.3318 - val_loss: 1.9486 - val_accuracy: 0.3800\n",
      "Episode 199\n",
      "10/10 [==============================] - 4s 378ms/step - loss: 2.1653 - accuracy: 0.3326 - val_loss: 1.8288 - val_accuracy: 0.3267\n",
      "Episode 200\n",
      "10/10 [==============================] - 5s 496ms/step - loss: 2.1361 - accuracy: 0.3422 - val_loss: 1.9136 - val_accuracy: 0.3533\n",
      "WARNING:tensorflow:AutoGraph could not transform <function trace_model_call.<locals>._wrapped_model at 0x7f0a205a27a0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7f0a1a75e170> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "INFO:tensorflow:Assets written to: /tmp/sepconvnn_tmp_dos_200/assets\n",
      "Episode 201\n",
      "10/10 [==============================] - 4s 424ms/step - loss: 2.1785 - accuracy: 0.3290 - val_loss: 1.8694 - val_accuracy: 0.3600\n",
      "Episode 202\n",
      "10/10 [==============================] - 4s 376ms/step - loss: 2.1506 - accuracy: 0.3422 - val_loss: 2.0797 - val_accuracy: 0.3067\n",
      "Episode 203\n",
      "10/10 [==============================] - 4s 376ms/step - loss: 2.1896 - accuracy: 0.3298 - val_loss: 1.8573 - val_accuracy: 0.3400\n",
      "Episode 204\n",
      "10/10 [==============================] - 4s 378ms/step - loss: 2.1717 - accuracy: 0.3310 - val_loss: 2.0698 - val_accuracy: 0.3200\n",
      "Episode 205\n",
      "10/10 [==============================] - 4s 377ms/step - loss: 2.1928 - accuracy: 0.3284 - val_loss: 1.8603 - val_accuracy: 0.4000\n",
      "Episode 206\n",
      "10/10 [==============================] - 4s 421ms/step - loss: 2.1573 - accuracy: 0.3366 - val_loss: 2.0223 - val_accuracy: 0.3800\n",
      "Episode 207\n",
      "10/10 [==============================] - 4s 374ms/step - loss: 2.1660 - accuracy: 0.3396 - val_loss: 1.7155 - val_accuracy: 0.4667\n",
      "Episode 208\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 4s 386ms/step - loss: 2.1537 - accuracy: 0.3308 - val_loss: 2.1438 - val_accuracy: 0.3000\n",
      "Episode 209\n",
      "10/10 [==============================] - 5s 501ms/step - loss: 2.1530 - accuracy: 0.3370 - val_loss: 2.2105 - val_accuracy: 0.3133\n",
      "Episode 210\n",
      "10/10 [==============================] - 4s 392ms/step - loss: 2.1720 - accuracy: 0.3300 - val_loss: 2.1127 - val_accuracy: 0.3333\n",
      "Episode 211\n",
      "10/10 [==============================] - 4s 401ms/step - loss: 2.1421 - accuracy: 0.3440 - val_loss: 2.0771 - val_accuracy: 0.3533\n",
      "Episode 212\n",
      "10/10 [==============================] - 4s 384ms/step - loss: 2.1672 - accuracy: 0.3338 - val_loss: 1.8566 - val_accuracy: 0.4533\n",
      "Episode 213\n",
      "10/10 [==============================] - 4s 390ms/step - loss: 2.1527 - accuracy: 0.3326 - val_loss: 1.7511 - val_accuracy: 0.3933\n",
      "Episode 214\n",
      "10/10 [==============================] - 4s 387ms/step - loss: 2.1710 - accuracy: 0.3276 - val_loss: 1.8666 - val_accuracy: 0.3600\n",
      "Episode 215\n",
      "10/10 [==============================] - 4s 386ms/step - loss: 2.1308 - accuracy: 0.3318 - val_loss: 2.0864 - val_accuracy: 0.3267\n",
      "Episode 216\n",
      "10/10 [==============================] - 4s 372ms/step - loss: 2.1148 - accuracy: 0.3382 - val_loss: 1.9592 - val_accuracy: 0.3800\n",
      "Episode 217\n",
      "10/10 [==============================] - 4s 380ms/step - loss: 2.1450 - accuracy: 0.3364 - val_loss: 1.8496 - val_accuracy: 0.4600\n",
      "Episode 218\n",
      "10/10 [==============================] - 4s 386ms/step - loss: 2.1678 - accuracy: 0.3264 - val_loss: 1.8948 - val_accuracy: 0.3800\n",
      "Episode 219\n",
      "10/10 [==============================] - 4s 377ms/step - loss: 2.1716 - accuracy: 0.3236 - val_loss: 1.9389 - val_accuracy: 0.3400\n",
      "Episode 220\n",
      "10/10 [==============================] - 4s 377ms/step - loss: 2.1498 - accuracy: 0.3346 - val_loss: 1.8716 - val_accuracy: 0.3800\n",
      "WARNING:tensorflow:AutoGraph could not transform <function trace_model_call.<locals>._wrapped_model at 0x7f0a2836a440> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7f0a1af099e0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "INFO:tensorflow:Assets written to: /tmp/sepconvnn_tmp_dos_220/assets\n",
      "Episode 221\n",
      "10/10 [==============================] - 4s 373ms/step - loss: 2.1579 - accuracy: 0.3440 - val_loss: 2.1317 - val_accuracy: 0.3400\n",
      "Episode 222\n",
      "10/10 [==============================] - 5s 510ms/step - loss: 2.1277 - accuracy: 0.3384 - val_loss: 2.0508 - val_accuracy: 0.3333\n",
      "Episode 223\n",
      "10/10 [==============================] - 4s 373ms/step - loss: 2.1266 - accuracy: 0.3454 - val_loss: 1.8173 - val_accuracy: 0.4000\n",
      "Episode 224\n",
      "10/10 [==============================] - 4s 399ms/step - loss: 2.1639 - accuracy: 0.3284 - val_loss: 1.9351 - val_accuracy: 0.4200\n",
      "Episode 225\n",
      "10/10 [==============================] - 5s 447ms/step - loss: 2.1739 - accuracy: 0.3226 - val_loss: 2.0175 - val_accuracy: 0.3667\n",
      "Episode 226\n",
      "10/10 [==============================] - 4s 369ms/step - loss: 2.1721 - accuracy: 0.3254 - val_loss: 1.9761 - val_accuracy: 0.3200\n",
      "Episode 227\n",
      "10/10 [==============================] - 4s 378ms/step - loss: 2.1796 - accuracy: 0.3326 - val_loss: 1.7927 - val_accuracy: 0.4000\n",
      "Episode 228\n",
      "10/10 [==============================] - 4s 368ms/step - loss: 2.1392 - accuracy: 0.3318 - val_loss: 2.2324 - val_accuracy: 0.2867\n",
      "Episode 229\n",
      "10/10 [==============================] - 4s 372ms/step - loss: 2.1424 - accuracy: 0.3288 - val_loss: 2.0672 - val_accuracy: 0.3333\n",
      "Episode 230\n",
      "10/10 [==============================] - 4s 371ms/step - loss: 2.1189 - accuracy: 0.3416 - val_loss: 1.9136 - val_accuracy: 0.3867\n",
      "Episode 231\n",
      "10/10 [==============================] - 4s 374ms/step - loss: 2.1476 - accuracy: 0.3378 - val_loss: 1.9607 - val_accuracy: 0.3867\n",
      "Episode 232\n",
      "10/10 [==============================] - 4s 375ms/step - loss: 2.1072 - accuracy: 0.3372 - val_loss: 1.9971 - val_accuracy: 0.4067\n",
      "Episode 233\n",
      "10/10 [==============================] - 4s 373ms/step - loss: 2.1188 - accuracy: 0.3436 - val_loss: 2.0557 - val_accuracy: 0.3600\n",
      "Episode 234\n",
      "10/10 [==============================] - 4s 371ms/step - loss: 2.1514 - accuracy: 0.3280 - val_loss: 1.8861 - val_accuracy: 0.3600\n",
      "Episode 235\n",
      "10/10 [==============================] - 5s 463ms/step - loss: 2.1305 - accuracy: 0.3456 - val_loss: 1.7472 - val_accuracy: 0.3933\n",
      "Episode 236\n",
      "10/10 [==============================] - 4s 403ms/step - loss: 2.1046 - accuracy: 0.3398 - val_loss: 1.8713 - val_accuracy: 0.3667\n",
      "Episode 237\n",
      "10/10 [==============================] - 4s 372ms/step - loss: 2.1191 - accuracy: 0.3426 - val_loss: 2.0752 - val_accuracy: 0.3533\n",
      "Episode 238\n",
      "10/10 [==============================] - 4s 370ms/step - loss: 2.1531 - accuracy: 0.3274 - val_loss: 1.8106 - val_accuracy: 0.4467\n",
      "Episode 239\n",
      "10/10 [==============================] - 4s 371ms/step - loss: 2.1159 - accuracy: 0.3428 - val_loss: 1.9107 - val_accuracy: 0.3200\n",
      "Episode 240\n",
      "10/10 [==============================] - 4s 371ms/step - loss: 2.1374 - accuracy: 0.3324 - val_loss: 2.0461 - val_accuracy: 0.3533\n",
      "WARNING:tensorflow:AutoGraph could not transform <function trace_model_call.<locals>._wrapped_model at 0x7f0a1ac2b200> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7f0a1ab37dd0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "INFO:tensorflow:Assets written to: /tmp/sepconvnn_tmp_dos_240/assets\n",
      "Episode 241\n",
      "10/10 [==============================] - 4s 372ms/step - loss: 2.1536 - accuracy: 0.3222 - val_loss: 1.7962 - val_accuracy: 0.3867\n",
      "Episode 242\n",
      "10/10 [==============================] - 4s 370ms/step - loss: 2.1047 - accuracy: 0.3588 - val_loss: 1.8353 - val_accuracy: 0.3600\n",
      "Episode 243\n",
      "10/10 [==============================] - 4s 375ms/step - loss: 2.1171 - accuracy: 0.3538 - val_loss: 2.0422 - val_accuracy: 0.2800\n",
      "Episode 244\n",
      "10/10 [==============================] - 4s 374ms/step - loss: 2.1278 - accuracy: 0.3428 - val_loss: 1.8848 - val_accuracy: 0.3733\n",
      "Episode 245\n",
      "10/10 [==============================] - 4s 373ms/step - loss: 2.1581 - accuracy: 0.3286 - val_loss: 1.9880 - val_accuracy: 0.3733\n",
      "Episode 246\n",
      "10/10 [==============================] - 4s 370ms/step - loss: 2.1328 - accuracy: 0.3388 - val_loss: 1.7990 - val_accuracy: 0.3800\n",
      "Episode 247\n",
      "10/10 [==============================] - 4s 369ms/step - loss: 2.1181 - accuracy: 0.3494 - val_loss: 1.7484 - val_accuracy: 0.4133\n",
      "Episode 248\n",
      "10/10 [==============================] - 4s 369ms/step - loss: 2.1326 - accuracy: 0.3320 - val_loss: 1.9091 - val_accuracy: 0.3533\n",
      "Episode 249\n",
      "10/10 [==============================] - 4s 429ms/step - loss: 2.1598 - accuracy: 0.3222 - val_loss: 1.9870 - val_accuracy: 0.3267\n",
      "Episode 250\n",
      "10/10 [==============================] - 4s 422ms/step - loss: 2.1310 - accuracy: 0.3356 - val_loss: 2.0041 - val_accuracy: 0.3200\n",
      "Episode 251\n",
      "10/10 [==============================] - 4s 372ms/step - loss: 2.1589 - accuracy: 0.3286 - val_loss: 1.8276 - val_accuracy: 0.3933\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 252\n",
      "10/10 [==============================] - 4s 377ms/step - loss: 2.1513 - accuracy: 0.3316 - val_loss: 1.8949 - val_accuracy: 0.3933\n",
      "Episode 253\n",
      "10/10 [==============================] - 4s 369ms/step - loss: 2.1424 - accuracy: 0.3320 - val_loss: 1.9743 - val_accuracy: 0.4067\n",
      "Episode 254\n",
      "10/10 [==============================] - 4s 374ms/step - loss: 2.1071 - accuracy: 0.3334 - val_loss: 2.1210 - val_accuracy: 0.3467\n",
      "Episode 255\n",
      "10/10 [==============================] - 4s 370ms/step - loss: 2.0941 - accuracy: 0.3370 - val_loss: 1.8504 - val_accuracy: 0.4067\n",
      "Episode 256\n",
      "10/10 [==============================] - 4s 371ms/step - loss: 2.1049 - accuracy: 0.3386 - val_loss: 2.0576 - val_accuracy: 0.3200\n",
      "Episode 257\n",
      "10/10 [==============================] - 4s 372ms/step - loss: 2.1390 - accuracy: 0.3378 - val_loss: 1.9283 - val_accuracy: 0.3867\n",
      "Episode 258\n",
      "10/10 [==============================] - 4s 366ms/step - loss: 2.1196 - accuracy: 0.3354 - val_loss: 1.8903 - val_accuracy: 0.3067\n",
      "Episode 259\n",
      "10/10 [==============================] - 4s 369ms/step - loss: 2.1190 - accuracy: 0.3432 - val_loss: 1.8343 - val_accuracy: 0.3600\n",
      "Episode 260\n",
      "10/10 [==============================] - 4s 372ms/step - loss: 2.0981 - accuracy: 0.3442 - val_loss: 1.9717 - val_accuracy: 0.3733\n",
      "WARNING:tensorflow:AutoGraph could not transform <function trace_model_call.<locals>._wrapped_model at 0x7f0a1a671f80> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7f0a1a5517a0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "INFO:tensorflow:Assets written to: /tmp/sepconvnn_tmp_dos_260/assets\n",
      "Episode 261\n",
      "10/10 [==============================] - 4s 375ms/step - loss: 2.1199 - accuracy: 0.3284 - val_loss: 1.8607 - val_accuracy: 0.4067\n",
      "Episode 262\n",
      "10/10 [==============================] - 4s 401ms/step - loss: 2.0782 - accuracy: 0.3396 - val_loss: 1.8217 - val_accuracy: 0.3933\n",
      "Episode 263\n",
      "10/10 [==============================] - 5s 486ms/step - loss: 2.1312 - accuracy: 0.3400 - val_loss: 1.8296 - val_accuracy: 0.3867\n",
      "Episode 264\n",
      "10/10 [==============================] - 4s 377ms/step - loss: 2.1186 - accuracy: 0.3262 - val_loss: 2.0289 - val_accuracy: 0.3267\n",
      "Episode 265\n",
      "10/10 [==============================] - 4s 373ms/step - loss: 2.1255 - accuracy: 0.3376 - val_loss: 1.7603 - val_accuracy: 0.4400\n",
      "Episode 266\n",
      "10/10 [==============================] - 4s 378ms/step - loss: 2.0995 - accuracy: 0.3448 - val_loss: 1.7316 - val_accuracy: 0.3933\n",
      "Episode 267\n",
      "10/10 [==============================] - 4s 380ms/step - loss: 2.1515 - accuracy: 0.3300 - val_loss: 1.8112 - val_accuracy: 0.3800\n",
      "Episode 268\n",
      "10/10 [==============================] - 4s 376ms/step - loss: 2.1301 - accuracy: 0.3368 - val_loss: 1.9443 - val_accuracy: 0.3933\n",
      "Episode 269\n",
      "10/10 [==============================] - 4s 378ms/step - loss: 2.1470 - accuracy: 0.3348 - val_loss: 2.0285 - val_accuracy: 0.3867\n",
      "Episode 270\n",
      "10/10 [==============================] - 4s 375ms/step - loss: 2.1247 - accuracy: 0.3374 - val_loss: 2.0073 - val_accuracy: 0.4067\n",
      "Episode 271\n",
      "10/10 [==============================] - 4s 375ms/step - loss: 2.1156 - accuracy: 0.3424 - val_loss: 2.0381 - val_accuracy: 0.3400\n",
      "Episode 272\n",
      "10/10 [==============================] - 4s 377ms/step - loss: 2.1372 - accuracy: 0.3374 - val_loss: 1.9015 - val_accuracy: 0.3400\n",
      "Episode 273\n",
      "10/10 [==============================] - 4s 375ms/step - loss: 2.1593 - accuracy: 0.3260 - val_loss: 1.8613 - val_accuracy: 0.3600\n",
      "Episode 274\n",
      "10/10 [==============================] - 4s 373ms/step - loss: 2.1129 - accuracy: 0.3372 - val_loss: 1.8505 - val_accuracy: 0.4467\n",
      "Episode 275\n",
      "10/10 [==============================] - 4s 372ms/step - loss: 2.1118 - accuracy: 0.3432 - val_loss: 2.1720 - val_accuracy: 0.3467\n",
      "Episode 276\n",
      "10/10 [==============================] - 4s 373ms/step - loss: 2.0860 - accuracy: 0.3470 - val_loss: 1.8599 - val_accuracy: 0.3600\n",
      "Episode 277\n",
      "10/10 [==============================] - 4s 378ms/step - loss: 2.1382 - accuracy: 0.3470 - val_loss: 1.8389 - val_accuracy: 0.4333\n",
      "Episode 278\n",
      "10/10 [==============================] - 4s 377ms/step - loss: 2.0890 - accuracy: 0.3492 - val_loss: 2.0395 - val_accuracy: 0.3467\n",
      "Episode 279\n",
      "10/10 [==============================] - 4s 380ms/step - loss: 2.0875 - accuracy: 0.3468 - val_loss: 1.6953 - val_accuracy: 0.4133\n",
      "Episode 280\n",
      "10/10 [==============================] - 4s 378ms/step - loss: 2.0878 - accuracy: 0.3452 - val_loss: 1.6724 - val_accuracy: 0.4400\n",
      "WARNING:tensorflow:AutoGraph could not transform <function trace_model_call.<locals>._wrapped_model at 0x7f0a28553560> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7f0a1a75e200> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "INFO:tensorflow:Assets written to: /tmp/sepconvnn_tmp_dos_280/assets\n",
      "Episode 281\n",
      "10/10 [==============================] - 4s 372ms/step - loss: 2.1144 - accuracy: 0.3330 - val_loss: 1.6824 - val_accuracy: 0.4067\n",
      "Episode 282\n",
      "10/10 [==============================] - 4s 373ms/step - loss: 2.1093 - accuracy: 0.3352 - val_loss: 1.9493 - val_accuracy: 0.3000\n",
      "Episode 283\n",
      "10/10 [==============================] - 4s 369ms/step - loss: 2.0842 - accuracy: 0.3460 - val_loss: 1.8031 - val_accuracy: 0.3467\n",
      "Episode 284\n",
      "10/10 [==============================] - 4s 426ms/step - loss: 2.0618 - accuracy: 0.3528 - val_loss: 2.0287 - val_accuracy: 0.3800\n",
      "Episode 285\n",
      "10/10 [==============================] - 6s 589ms/step - loss: 2.0789 - accuracy: 0.3422 - val_loss: 1.8626 - val_accuracy: 0.3800\n",
      "Episode 286\n",
      "10/10 [==============================] - 4s 372ms/step - loss: 2.1067 - accuracy: 0.3410 - val_loss: 1.7456 - val_accuracy: 0.4467\n",
      "Episode 287\n",
      "10/10 [==============================] - 4s 374ms/step - loss: 2.1212 - accuracy: 0.3376 - val_loss: 1.9210 - val_accuracy: 0.3333\n",
      "Episode 288\n",
      "10/10 [==============================] - 4s 378ms/step - loss: 2.0908 - accuracy: 0.3500 - val_loss: 1.8636 - val_accuracy: 0.3733\n",
      "Episode 289\n",
      "10/10 [==============================] - 4s 385ms/step - loss: 2.1475 - accuracy: 0.3422 - val_loss: 1.9963 - val_accuracy: 0.3467\n",
      "Episode 290\n",
      "10/10 [==============================] - 4s 371ms/step - loss: 2.1112 - accuracy: 0.3376 - val_loss: 1.9534 - val_accuracy: 0.4133\n",
      "Episode 291\n",
      "10/10 [==============================] - 4s 385ms/step - loss: 2.1092 - accuracy: 0.3456 - val_loss: 1.9097 - val_accuracy: 0.3733\n",
      "Episode 292\n",
      "10/10 [==============================] - 4s 373ms/step - loss: 2.0764 - accuracy: 0.3566 - val_loss: 1.9666 - val_accuracy: 0.3933\n",
      "Episode 293\n",
      "10/10 [==============================] - 4s 372ms/step - loss: 2.1318 - accuracy: 0.3310 - val_loss: 2.1357 - val_accuracy: 0.2667\n",
      "Episode 294\n",
      "10/10 [==============================] - 4s 371ms/step - loss: 2.1196 - accuracy: 0.3432 - val_loss: 1.9330 - val_accuracy: 0.3933\n",
      "Episode 295\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 4s 374ms/step - loss: 2.1163 - accuracy: 0.3430 - val_loss: 1.9538 - val_accuracy: 0.3400\n",
      "Episode 296\n",
      "10/10 [==============================] - 4s 371ms/step - loss: 2.0988 - accuracy: 0.3386 - val_loss: 1.8903 - val_accuracy: 0.3667\n",
      "Episode 297\n",
      "10/10 [==============================] - 4s 373ms/step - loss: 2.0870 - accuracy: 0.3438 - val_loss: 1.9273 - val_accuracy: 0.3333\n",
      "Episode 298\n",
      "10/10 [==============================] - 4s 374ms/step - loss: 2.0821 - accuracy: 0.3462 - val_loss: 1.9020 - val_accuracy: 0.3333\n",
      "Episode 299\n",
      "10/10 [==============================] - 4s 371ms/step - loss: 2.0885 - accuracy: 0.3556 - val_loss: 1.8622 - val_accuracy: 0.3600\n",
      "Episode 300\n",
      "10/10 [==============================] - 4s 369ms/step - loss: 2.0830 - accuracy: 0.3390 - val_loss: 1.9464 - val_accuracy: 0.3533\n",
      "WARNING:tensorflow:AutoGraph could not transform <function trace_model_call.<locals>._wrapped_model at 0x7f0a28553560> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7f0a1a2b2170> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "INFO:tensorflow:Assets written to: /tmp/sepconvnn_tmp_dos_300/assets\n"
     ]
    }
   ],
   "source": [
    "results = {}\n",
    "results[\"loss\"] = []\n",
    "results[\"accuracy\"] = []\n",
    "results[\"val_loss\"] = []\n",
    "results[\"val_accuracy\"] = []\n",
    "\n",
    "results[\"binaries_errors\"] = []\n",
    "results[\"binaries_errors_top2\"] = []\n",
    "results[\"binaries_mse\"] = []\n",
    "\n",
    "results[\"bedding_errors\"] = []\n",
    "results[\"bedding_errors_top2\"] = []\n",
    "results[\"bedding_mse\"] = []\n",
    "\n",
    "\n",
    "_index = np.array([i for i in range(100)], dtype=np.int32)\n",
    "_index\n",
    "class_weight_dict = {}\n",
    "for e in _index:\n",
    "    class_weight_dict[int(e ) * 1.0] = 0.2\n",
    "print(class_weight_dict)\n",
    "\n",
    "\n",
    "higher_n_probs = 10\n",
    "loops = 1\n",
    "for loop in range(loops):\n",
    "    print(\"Loop %s\" % loop)\n",
    "    sepconv_mod = models.separableconvnn()  # init model\n",
    "    sepconv_mod.compile(learning_rate=0.01)  # compile model\n",
    "\n",
    "    for ep in range(300 + 1):\n",
    "        print(\"Episode %s\" % ep)\n",
    "        history = sepconv_mod.model.fit(\n",
    "            # df_train,\n",
    "            df_train,\n",
    "            validation_data=df_validation,\n",
    "            validation_steps=1,\n",
    "            steps_per_epoch=10,\n",
    "            epochs=1,\n",
    "            #class_weight=class_weight_dict,\n",
    "            verbose=True,\n",
    "        )\n",
    "\n",
    "        if ep % 20 == 0:\n",
    "            sepconv_mod.save(\"/tmp/sepconvnn_tmp_dos_%s\" % ep)  # tmp model save\n",
    "\n",
    "        results[\"loss\"].append(history.history[\"loss\"][0])\n",
    "        results[\"accuracy\"].append(history.history[\"accuracy\"][0])\n",
    "        results[\"val_loss\"].append(history.history[\"val_loss\"][0])\n",
    "        results[\"val_accuracy\"].append(history.history[\"val_accuracy\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0.0: 0.2,\n",
       " 1.0: 0.2,\n",
       " 2.0: 0.2,\n",
       " 3.0: 0.2,\n",
       " 4.0: 0.2,\n",
       " 5.0: 0.2,\n",
       " 6.0: 0.2,\n",
       " 7.0: 0.2,\n",
       " 8.0: 0.2,\n",
       " 9.0: 0.2,\n",
       " 10.0: 0.2,\n",
       " 11.0: 0.2,\n",
       " 12.0: 0.2,\n",
       " 13.0: 0.2,\n",
       " 14.0: 0.2,\n",
       " 15.0: 0.2,\n",
       " 16.0: 0.2,\n",
       " 17.0: 0.2,\n",
       " 18.0: 0.2,\n",
       " 19.0: 0.2,\n",
       " 20.0: 0.2,\n",
       " 21.0: 0.2,\n",
       " 22.0: 0.2,\n",
       " 23.0: 0.2,\n",
       " 24.0: 0.2,\n",
       " 25.0: 0.2,\n",
       " 26.0: 0.2,\n",
       " 27.0: 0.2,\n",
       " 28.0: 0.2,\n",
       " 29.0: 0.2,\n",
       " 30.0: 0.2,\n",
       " 31.0: 0.2,\n",
       " 32.0: 0.2,\n",
       " 33.0: 0.2,\n",
       " 34.0: 0.2,\n",
       " 35.0: 0.2,\n",
       " 36.0: 0.2,\n",
       " 37.0: 0.2,\n",
       " 38.0: 0.2,\n",
       " 39.0: 0.2,\n",
       " 40.0: 0.2,\n",
       " 41.0: 0.2,\n",
       " 42.0: 0.2,\n",
       " 43.0: 0.2,\n",
       " 44.0: 0.2,\n",
       " 45.0: 0.2,\n",
       " 46.0: 0.2,\n",
       " 47.0: 0.2,\n",
       " 48.0: 0.2,\n",
       " 49.0: 0.2,\n",
       " 50.0: 0.2,\n",
       " 51.0: 0.2,\n",
       " 52.0: 0.2,\n",
       " 53.0: 0.2,\n",
       " 54.0: 0.2,\n",
       " 55.0: 0.2,\n",
       " 56.0: 0.2,\n",
       " 57.0: 0.2,\n",
       " 58.0: 0.2,\n",
       " 59.0: 0.2,\n",
       " 60.0: 0.2,\n",
       " 61.0: 0.2,\n",
       " 62.0: 0.2,\n",
       " 63.0: 0.2,\n",
       " 64.0: 0.2,\n",
       " 65.0: 0.2,\n",
       " 66.0: 0.2,\n",
       " 67.0: 0.2,\n",
       " 68.0: 0.2,\n",
       " 69.0: 0.2,\n",
       " 70.0: 0.2,\n",
       " 71.0: 0.2,\n",
       " 72.0: 0.2,\n",
       " 73.0: 0.2,\n",
       " 74.0: 0.2,\n",
       " 75.0: 0.2,\n",
       " 76.0: 0.2,\n",
       " 77.0: 0.2,\n",
       " 78.0: 0.2,\n",
       " 79.0: 0.2,\n",
       " 80.0: 0.2,\n",
       " 81.0: 0.2,\n",
       " 82.0: 0.2,\n",
       " 83.0: 0.2,\n",
       " 84.0: 0.2,\n",
       " 85.0: 0.2,\n",
       " 86.0: 0.2,\n",
       " 87.0: 0.2,\n",
       " 88.0: 0.2,\n",
       " 89.0: 0.2,\n",
       " 90.0: 0.2,\n",
       " 91.0: 0.2,\n",
       " 92.0: 0.2,\n",
       " 93.0: 0.2,\n",
       " 94.0: 0.2,\n",
       " 95.0: 0.2,\n",
       " 96.0: 0.2,\n",
       " 97.0: 0.2,\n",
       " 98.0: 0.2,\n",
       " 99.0: 0.2}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_weight_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Sequential' object has no attribute 'predict_proba'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-b10a8c39f45d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstar\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflat\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0ml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstar\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mprobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msepconv_mod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstar\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Sequential' object has no attribute 'predict_proba'"
     ]
    }
   ],
   "source": [
    "x = []\n",
    "y = []\n",
    "l = []\n",
    "for star in ds_stars:\n",
    "    target = np.where(star[2].numpy().flat == 1)[0].flat[0]\n",
    "    l.append(star[0].numpy()[0].decode(\"utf-8\"))\n",
    "    probs = sepconv_mod.model.predict_proba(star[1])[0]\n",
    "\n",
    "    print(l)\n",
    "    plt.plot(probs)\n",
    "    plt.show()\n",
    "\n",
    "    plt.plot(np.arange(0, 100, 0.25), star[1][0, :, 0], label=\"dft\", color=\"blue\")\n",
    "    # plt.plot(x, star[1][0, :, 1], label=\"hod\", color=\"orange\", alpha=0.5)\n",
    "    plt.plot(np.arange(0, 100, 0.25), star[1][0, :, 1], label=\"ac\", color=\"green\")\n",
    "    plt.show()\n",
    "    peaks, _ = find_peaks(probs, height=0, distance=5)\n",
    "    peaks_width = peak_widths(probs, peaks)\n",
    "    peaks_sorted_by_prob = np.sort(probs[peaks])[::-1]\n",
    "    best_peak, best_peak_width = get_peak_width(\n",
    "        0, peaks, peaks_width, peaks_sorted_by_prob\n",
    "    )\n",
    "    x.append(best_peak)\n",
    "    y.append(target)\n",
    "\n",
    "plt.scatter(y, x, label=l)\n",
    "print(np.asarray(x) - np.asarray(y))\n",
    "print(np.mean(np.asarray(x) - np.asarray(y)))\n",
    "print(np.mean(np.power(np.asarray(x) - np.asarray(y), 2)))\n",
    "print(x)\n",
    "print(y)\n",
    "print(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(results[\"loss\"])\n",
    "plt.plot(results[\"val_loss\"])\n",
    "plt.title(\"model loss\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.legend([\"train\", \"validation\"], loc=\"upper left\")\n",
    "plt.show()\n",
    "\n",
    "plt.plot(results[\"accuracy\"])\n",
    "plt.plot(results[\"val_accuracy\"])\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.legend([\"train\", \"validation\"], loc=\"upper left\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [i for i in range(len(results[\"binaries_errors\"]))]\n",
    "y = results[\"binaries_errors\"]\n",
    "m, b = np.polyfit(x, y, 1)\n",
    "plt.plot(x, m * np.asarray(x) + b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [i for i in range(len(results[\"bedding_errors\"]))]\n",
    "y = results[\"bedding_errors\"]\n",
    "m, b = np.polyfit(x, y, 1)\n",
    "plt.plot(x, m * np.asarray(x) + b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "targets = {}\n",
    "targets[\"kic10661783\"] = {\"dnu\": 39.0, \"dr\": 7.0}\n",
    "targets[\"KIC9851944\"] = {\"dnu\": 26.0, \"dr\": 5.3}\n",
    "targets[\"HD159561\"] = {\"dnu\": 38.0, \"dr\": 19.0}\n",
    "targets[\"CID100866999\"] = {\"dnu\": 56, \"dr\": np.nan}\n",
    "targets[\"HD15082\"] = {\"dnu\": 80.0, \"dr\": 14.0}\n",
    "targets[\"kic4544587\"] = {\"dnu\": 74.0, \"dr\": 11.0}\n",
    "targets[\"KIC8262223\"] = {\"dnu\": 77.0, \"dr\": 7.10}\n",
    "targets[\"HD172189\"] = {\"dnu\": 19.0, \"dr\": 4.6}\n",
    "targets[\"KIC3858884\"] = {\"dnu\": 19.0, \"dr\": 1.9}\n",
    "targets[\"CID105906206\"] = {\"dnu\": 20.0, \"dr\": 2.61}\n",
    "targets[\"KIC10080943\"] = {\"dnu\": 52.0, \"dr\": 1.7}\n",
    "\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.colors as mcolors\n",
    "\n",
    "# setup the normalization and the colormap\n",
    "normalize = mcolors.Normalize(vmin=0, vmax=higher_n_probs)\n",
    "colormap = plt.get_cmap(\"jet_r\")\n",
    "# setup the colorbar\n",
    "scalarmappaple = cm.ScalarMappable(norm=normalize, cmap=colormap)\n",
    "scalarmappaple.set_array(higher_n_probs)\n",
    "\n",
    "for star in results.keys():\n",
    "    if star in targets.keys():\n",
    "        for idx, val in enumerate(range(higher_n_probs)):\n",
    "            plt.plot(\n",
    "                results[star][(val,)],\n",
    "                alpha=0.5,\n",
    "                marker=\"o\",\n",
    "                linestyle=\"None\",\n",
    "                color=colormap(normalize(idx)),\n",
    "                markersize=higher_n_probs - idx,\n",
    "            )\n",
    "        plt.xlabel(\"NN epoch traininng (class infered)\")\n",
    "        plt.ylabel(r\"Frequency ($\\mu$hz)\")\n",
    "        plt.axhline(y=targets[star][\"dnu\"], color=\"black\")\n",
    "        plt.title(star)\n",
    "        plt.ylim(0, 100)\n",
    "        cbar = plt.colorbar(scalarmappaple)\n",
    "        cbar.set_label(\"Inference order (by probability)\")\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f1a770bbd7d56546fd23d64fa36e2d8465fea16bd5a1c87d5c9655e206fccc33"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
